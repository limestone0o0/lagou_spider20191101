2019-11-06 11:16:52 [scrapy.core.scraper] ERROR: Error processing {'art_company_id': 320770,
 'art_company_name': '爱笔（北京）智能科技有限公司',
 'art_description': '<p><strong>工作职责：</strong></p>\n'
                    '<p>1. 负责机器人团队PoC产品工程方面的快速实现验证</p>\n'
                    '<p>2. 负责机器人团队工程化</p>\n'
                    '<p><br></p>\n'
                    '<p><strong>任职条件：</strong></p>\n'
                    '<p>1、3年以上后端开发经验；</p>\n'
                    '<p>2、精通Python开发，熟悉Tornado等Web框架；</p>\n'
                    '<p>3、C/C++/Golang语言，熟悉其中一种优先；</p>\n'
                    '<p>4、熟悉Linux系统，具备高并发调度开发经验；</p>\n'
                    '<p>5、熟练掌握MySQL、Redis数据库；</p>\n'
                    '<p>6、理解HTTP/HTTPS、TCP/IP协议，熟悉常用服务网络架构；</p>\n'
                    '<p>7、扎实的计算机基础，熟悉数据结构，有较强的算法设计能力；</p>\n'
                    '<p>8、学习能力强，有较好的沟通能力，能迅速融入团队；</p>',
 'art_education': '本科',
 'art_first_type': '开发|测试|运维类',
 'art_jobNature': '全职',
 'art_position': '海淀区',
 'art_salary': '15k-30k',
 'art_second_type': '后端开发',
 'art_third_type': '开发|测试|运维类',
 'art_time': '2019-11-06 10:55:50',
 'art_title': 'python开发工程师-机器人',
 'art_work_year': '3-5年',
 'compangy_full_position': ', -\n'
                           '                    ,\n'
                           '                                            - '
                           '北清路81号\n'
                           '                                                            '
                           ',',
 'company_financestage': 'A轮',
 'company_hitags': '',
 'company_label_list': '国际化团队,计算机视觉,语音识别,自然语言理解',
 'company_size': '150-500人',
 'company_type': '移动互联网,企业服务',
 'fingerprint': '50b9f930816c6eeee4bcbed4117bf786',
 'positionId': 6277175}
Traceback (most recent call last):
  File "c:\programdata\anaconda3\envs\spiderpath\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy\lagouzhaopin\lagouzhaopin\pipelines.py", line 70, in process_item
    art.suggest = gen_suggest(LagouType._doc_type.index,((art.art_title,10),(art.art_position,7),
  File "E:\scrapy\lagouzhaopin\lagouzhaopin\pipelines.py", line 32, in gen_suggest
    words = es.indices.analyze(index=index, analyzer='ik_max_word',params={'filter':['lowercase']}, body=text)
  File "c:\programdata\anaconda3\envs\spiderpath\lib\site-packages\elasticsearch\client\utils.py", line 73, in _wrapped
    return func(*args, params=params, **kwargs)
  File "c:\programdata\anaconda3\envs\spiderpath\lib\site-packages\elasticsearch\client\indices.py", line 32, in analyze
    '_analyze'), params=params, body=body)
  File "c:\programdata\anaconda3\envs\spiderpath\lib\site-packages\elasticsearch\transport.py", line 312, in perform_request
    status, headers, data = connection.perform_request(method, url, params, body, ignore=ignore, timeout=timeout)
  File "c:\programdata\anaconda3\envs\spiderpath\lib\site-packages\elasticsearch\connection\http_urllib3.py", line 129, in perform_request
    self._raise_error(response.status, raw_data)
  File "c:\programdata\anaconda3\envs\spiderpath\lib\site-packages\elasticsearch\connection\base.py", line 125, in _raise_error
    raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
elasticsearch.exceptions.NotFoundError: TransportError(404, 'index_not_found_exception', 'no such index')
2019-11-06 13:21:58 [scrapy.core.scraper] ERROR: Error processing {'art_company_id': 442174,
 'art_company_name': '北京码上赢科技有限公司',
 'art_description': '<p>工作职责：<br></p>\n'
                    '<p>1. 负责数据生产工作流的开发与优化</p>\n'
                    '<p>2. 负责业务数据分析计算及数据存储，查询接口</p>\n'
                    '<p>3. 开发工作流相关工具与报表，提高数据生产性能，稳定性</p>\n'
                    '<p><br></p>\n'
                    '<p>岗位要求：</p>\n'
                    '<p>1. 计算机相关专业、本科及以上学历</p>\n'
                    '<p>2. 精通Python语言，熟练使用 Python Web 开发框架</p>\n'
                    '<p>3. 精通关系数据库（PG、MySQL等）和sqlalchemy等ORM系统，熟悉NoSQL数据库</p>\n'
                    '<p>4. 熟练使用linux/Unix常用操作命令，熟悉 bash shell 编程</p>\n'
                    '<p>5. 有工作流，大规模集群数据处理工作经验者优先</p>',
 'art_education': '本科',
 'art_first_type': '开发|测试|运维类',
 'art_jobNature': '全职',
 'art_position': '朝阳区',
 'art_salary': '15k-25k',
 'art_second_type': '后端开发',
 'art_third_type': 'Python',
 'art_time': '2019-11-06 12:54:50',
 'art_title': 'Python数据开发工程师',
 'art_work_year': '3-5年',
 'compangy_full_position': ', -\n'
                           '                    ,\n'
                           '                                            - '
                           '三元桥时间国际A座1609\n'
                           '                                                            '
                           ',',
 'company_financestage': 'A轮',
 'company_hitags': '',
 'company_label_list': '弹性工作,五险一金,阿里系,牛人多',
 'company_size': '50-150人',
 'company_type': '移动互联网,企业服务',
 'fingerprint': 'cb684e9f9ac2e68493b96a7c064a7ed5',
 'positionId': 6155531}
Traceback (most recent call last):
  File "c:\programdata\anaconda3\envs\spiderpath\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy\lagouzhaopin\lagouzhaopin\pipelines.py", line 70, in process_item
    art.suggest = gen_suggest(LagouType._doc_type.index,((art.art_title,10),(art.art_position,7),
  File "E:\scrapy\lagouzhaopin\lagouzhaopin\pipelines.py", line 32, in gen_suggest
    words = es.indices.analyze(index=index, analyzer='ik_max_word',params={'filter':['lowercase']}, body=text)
  File "c:\programdata\anaconda3\envs\spiderpath\lib\site-packages\elasticsearch\client\utils.py", line 73, in _wrapped
    return func(*args, params=params, **kwargs)
  File "c:\programdata\anaconda3\envs\spiderpath\lib\site-packages\elasticsearch\client\indices.py", line 32, in analyze
    '_analyze'), params=params, body=body)
  File "c:\programdata\anaconda3\envs\spiderpath\lib\site-packages\elasticsearch\transport.py", line 312, in perform_request
    status, headers, data = connection.perform_request(method, url, params, body, ignore=ignore, timeout=timeout)
  File "c:\programdata\anaconda3\envs\spiderpath\lib\site-packages\elasticsearch\connection\http_urllib3.py", line 129, in perform_request
    self._raise_error(response.status, raw_data)
  File "c:\programdata\anaconda3\envs\spiderpath\lib\site-packages\elasticsearch\connection\base.py", line 125, in _raise_error
    raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
elasticsearch.exceptions.NotFoundError: TransportError(404, 'index_not_found_exception', 'no such index')
2019-11-06 13:22:00 [scrapy.core.scraper] ERROR: Error processing {'art_company_id': 133165,
 'art_company_name': '南京厚建云计算有限公司广州分公司',
 'art_description': '<p>任职要求：</p>\n'
                    '<p>1. 本科及以上学历；</p>\n'
                    '<p>2.不错的英文读写功力，阅读python相关技术文档，热爱Python，对自己的代码风格要求严格，有技术热情，执行力强。</p>\n'
                    '<p>3. 熟练使用Python语言，对操作系统和Linux内核有了解；</p>\n'
                    '<p>4. 学习成绩优秀，学习能力强，适应能力好；</p>\n'
                    '<p>&nbsp;</p>\n'
                    '<p>岗位职责：</p>\n'
                    '<p>1. 负责Python小项目及局部模块的任务开发；</p>\n'
                    '<p>2. 按主管要求负责项目设计，并进行编码；</p>\n'
                    '<p>3. 根据开发规范与流程独立完成编码，测试及相关文档。</p>',
 'art_education': '本科',
 'art_first_type': '开发|测试|运维类',
 'art_jobNature': '全职',
 'art_position': '番禺区',
 'art_salary': '2k-3k',
 'art_second_type': '后端开发',
 'art_third_type': 'Python',
 'art_time': '2019-11-06 12:07:42',
 'art_title': 'Python后端开发实习',
 'art_work_year': '不限',
 'compangy_full_position': ', -\n'
                           '                    , -\n'
                           '                    ,\n'
                           '                                            - '
                           '迎宾大道五洲商务中心C座6006\n'
                           '                                                            '
                           ',',
 'company_financestage': '不需要融资',
 'company_hitags': '',
 'company_label_list': '五险一金,岗位晋升,扁平管理,定期体检',
 'company_size': '50-150人',
 'company_type': '移动互联网,企业服务',
 'fingerprint': '653586eb385e04467006676d6398568f',
 'positionId': 6522140}
Traceback (most recent call last):
  File "c:\programdata\anaconda3\envs\spiderpath\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy\lagouzhaopin\lagouzhaopin\pipelines.py", line 70, in process_item
    art.suggest = gen_suggest(LagouType._doc_type.index,((art.art_title,10),(art.art_position,7),
  File "E:\scrapy\lagouzhaopin\lagouzhaopin\pipelines.py", line 32, in gen_suggest
    words = es.indices.analyze(index=index, analyzer='ik_max_word',params={'filter':['lowercase']}, body=text)
  File "c:\programdata\anaconda3\envs\spiderpath\lib\site-packages\elasticsearch\client\utils.py", line 73, in _wrapped
    return func(*args, params=params, **kwargs)
  File "c:\programdata\anaconda3\envs\spiderpath\lib\site-packages\elasticsearch\client\indices.py", line 32, in analyze
    '_analyze'), params=params, body=body)
  File "c:\programdata\anaconda3\envs\spiderpath\lib\site-packages\elasticsearch\transport.py", line 312, in perform_request
    status, headers, data = connection.perform_request(method, url, params, body, ignore=ignore, timeout=timeout)
  File "c:\programdata\anaconda3\envs\spiderpath\lib\site-packages\elasticsearch\connection\http_urllib3.py", line 129, in perform_request
    self._raise_error(response.status, raw_data)
  File "c:\programdata\anaconda3\envs\spiderpath\lib\site-packages\elasticsearch\connection\base.py", line 125, in _raise_error
    raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
elasticsearch.exceptions.NotFoundError: TransportError(404, 'index_not_found_exception', 'no such index')
2019-11-06 13:22:01 [scrapy.core.scraper] ERROR: Error processing {'art_company_id': 35322,
 'art_company_name': '北京缔联科技有限公司',
 'art_description': '<p><strong>【技能要求】<br></strong><span class=" '
                    '"><strong><span class="  '
                    'ueditor_underline">1.自有B端产品经验；</span><br><span class="  '
                    'ueditor_underline">2.熟练使用tornado；<br></span></strong></span><span '
                    'class="  '
                    'ueditor_underline"><strong>3.web服务。</strong></span></p>\n'
                    '<p>〖岗位要求〗</p>\n'
                    '<p>1. 根据业务需求，可独立完成技术可行性报告、概要设计、详细设计、并撰写相关文档；</p>\n'
                    '<p>2. 搭建系统开发环境，完成系统框架与核心代码开发。</p>\n'
                    '<p>〖任职要求〗</p>\n'
                    '<p>1. 熟悉python语言服务端开发，3年以上开发经验；</p>\n'
                    '<p>2. 熟练使用tornado等python框架，熟悉asyncio库，有自有B端项目经验者优先；</p>\n'
                    '<p>3. 具有良好的编程思想、沟通、团队合作精神、优秀的分析问题和解决问题的能力；</p>\n'
                    '<p>4. 学习能力强，乐于钻研，较强的抗压能力。</p>',
 'art_education': '本科',
 'art_first_type': '开发|测试|运维类',
 'art_jobNature': '全职',
 'art_position': '海淀区',
 'art_salary': '15k-30k',
 'art_second_type': '后端开发',
 'art_third_type': 'Python',
 'art_time': '2019-11-06 11:47:52',
 'art_title': 'python开发工程师',
 'art_work_year': '3-5年',
 'compangy_full_position': ', -\n'
                           '                    , -\n'
                           '                    ,\n'
                           '                                            - '
                           '中关村大街15-11号B2层C02室（创业公社大厦）\n'
                           '                                                            '
                           ',',
 'company_financestage': 'B轮',
 'company_hitags': '',
 'company_label_list': '年底双薪,节日礼物,年度旅游,岗位晋升',
 'company_size': '50-150人',
 'company_type': '企业服务',
 'fingerprint': 'd5748985d44b729eebb9600552cfef13',
 'positionId': 6164923}
Traceback (most recent call last):
  File "c:\programdata\anaconda3\envs\spiderpath\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy\lagouzhaopin\lagouzhaopin\pipelines.py", line 70, in process_item
    art.suggest = gen_suggest(LagouType._doc_type.index,((art.art_title,10),(art.art_position,7),
  File "E:\scrapy\lagouzhaopin\lagouzhaopin\pipelines.py", line 32, in gen_suggest
    words = es.indices.analyze(index=index, analyzer='ik_max_word',params={'filter':['lowercase']}, body=text)
  File "c:\programdata\anaconda3\envs\spiderpath\lib\site-packages\elasticsearch\client\utils.py", line 73, in _wrapped
    return func(*args, params=params, **kwargs)
  File "c:\programdata\anaconda3\envs\spiderpath\lib\site-packages\elasticsearch\client\indices.py", line 32, in analyze
    '_analyze'), params=params, body=body)
  File "c:\programdata\anaconda3\envs\spiderpath\lib\site-packages\elasticsearch\transport.py", line 312, in perform_request
    status, headers, data = connection.perform_request(method, url, params, body, ignore=ignore, timeout=timeout)
  File "c:\programdata\anaconda3\envs\spiderpath\lib\site-packages\elasticsearch\connection\http_urllib3.py", line 129, in perform_request
    self._raise_error(response.status, raw_data)
  File "c:\programdata\anaconda3\envs\spiderpath\lib\site-packages\elasticsearch\connection\base.py", line 125, in _raise_error
    raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
elasticsearch.exceptions.NotFoundError: TransportError(404, 'index_not_found_exception', 'no such index')
2019-11-06 13:22:03 [scrapy.core.scraper] ERROR: Error processing {'art_company_id': 292539,
 'art_company_name': '广州掌昆网络科技有限公司',
 'art_description': '<p>说明：面向20届本科生，无需经验，潜力为你撑腰，提供转正编制。</p>\n'
                    '<p>【岗位职责】</p>\n'
                    '<p>1、负责游戏渠道数据平台的开发及维护；</p>\n'
                    '<p>【任职要求】</p>\n'
                    '<p>1、学历: 本科及以上</p>\n'
                    '<p>2、专业: 计算机/通信相关专业即可</p>\n'
                    '<p>3、兴趣: 对开源感兴趣, 喜欢研究新技术</p>\n'
                    '<p>4、其他: 学习能力强，有迎难而上的精神</p>\n'
                    '<p><br></p>\n'
                    '<p>【关于福利】</p>\n'
                    '<p>1、基本福利：平均15薪、七险一金、周末双休、带薪年假、年度体检</p>\n'
                    '<p>2、花样活动：每周运动会、月度聚餐、季度生日会、年度旅游、年度晚宴</p>\n'
                    '<p>3、薪酬体系：有竞争力的薪资待遇、年终奖、全勤奖、双薪、内推伯乐奖</p>\n'
                    '<p>4、便利生活：自助午晚餐、下午茶，零食饮料随时供应，加班车费公司付</p>\n'
                    '<p>5、暖心惊喜：入职纪念品、婚育礼金、生日礼物、周年大礼包、年节纪念品</p>\n'
                    '<p>【关于成长】</p>\n'
                    '<p>1、晋升机会：只论能力不论年资，提供双通道的成长路径，大神们带你快速升级</p>\n'
                    '<p>2、专业培训：入职培训、岗位导师制、不定期内外部分享会、读书角</p>\n'
                    '<p>3、调薪机会：一年两次调薪、根据自身能力的变化而提升</p>\n'
                    '<p>【关于周边】</p>\n'
                    '<p>1、地铁周边：地铁4、8号线万胜围站D出口，出站后需步行5-8分钟</p>\n'
                    '<p>2、工作时间：9:30~12:00，13:30~18:30，弹性上班制</p>\n'
                    '<p>3、办公环境：甲级江景写字楼、躺式办公椅午睡不用愁、健身房、书吧角</p>\n'
                    '<p>4、团队氛围：平均年龄25岁，简单的人、做专注的事、追求卓越、收获战功</p>\n'
                    '<p><br></p>\n'
                    '<p>作为一家正在蓬勃发展的公司，我们有技术大牛、靠谱的伙伴、雄厚的资金实力，欢迎热爱游戏、怀揣梦想、有激情的你随时加入！</p>',
 'art_education': '本科',
 'art_first_type': '开发|测试|运维类',
 'art_jobNature': '全职',
 'art_position': '海珠区',
 'art_salary': '5k-8k',
 'art_second_type': '后端开发',
 'art_third_type': 'Python',
 'art_time': '2019-11-06 11:31:13',
 'art_title': 'python实习',
 'art_work_year': '应届毕业生',
 'compangy_full_position': ', -\n'
                           '                    ,\n'
                           '                                            - '
                           '广州市海珠区阅江中路暄悦东街23号中悦广场37楼\n'
                           '                                                            '
                           ',',
 'company_financestage': '不需要融资',
 'company_hitags': '',
 'company_label_list': '绩效奖金,年底双薪,年终分红,带薪年假',
 'company_size': '150-500人',
 'company_type': '移动互联网,游戏',
 'fingerprint': '9ab425391102d04f24a82e0598e6ee7b',
 'positionId': 6257860}
Traceback (most recent call last):
  File "c:\programdata\anaconda3\envs\spiderpath\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy\lagouzhaopin\lagouzhaopin\pipelines.py", line 70, in process_item
    art.suggest = gen_suggest(LagouType._doc_type.index,((art.art_title,10),(art.art_position,7),
  File "E:\scrapy\lagouzhaopin\lagouzhaopin\pipelines.py", line 32, in gen_suggest
    words = es.indices.analyze(index=index, analyzer='ik_max_word',params={'filter':['lowercase']}, body=text)
  File "c:\programdata\anaconda3\envs\spiderpath\lib\site-packages\elasticsearch\client\utils.py", line 73, in _wrapped
    return func(*args, params=params, **kwargs)
  File "c:\programdata\anaconda3\envs\spiderpath\lib\site-packages\elasticsearch\client\indices.py", line 32, in analyze
    '_analyze'), params=params, body=body)
  File "c:\programdata\anaconda3\envs\spiderpath\lib\site-packages\elasticsearch\transport.py", line 312, in perform_request
    status, headers, data = connection.perform_request(method, url, params, body, ignore=ignore, timeout=timeout)
  File "c:\programdata\anaconda3\envs\spiderpath\lib\site-packages\elasticsearch\connection\http_urllib3.py", line 129, in perform_request
    self._raise_error(response.status, raw_data)
  File "c:\programdata\anaconda3\envs\spiderpath\lib\site-packages\elasticsearch\connection\base.py", line 125, in _raise_error
    raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
elasticsearch.exceptions.NotFoundError: TransportError(404, 'index_not_found_exception', 'no such index')
2019-11-06 13:22:04 [scrapy.core.scraper] ERROR: Error processing {'art_company_id': 130397,
 'art_company_name': '深圳小步网络科技有限公司',
 'art_description': '<p>岗位职责：<br></p>\n'
                    '<p>1.&nbsp;负责公司产品后台服务的搭建和编码实现；<br>2.&nbsp;负责公司后台性能优化，与产品协作提升产品数据；<br>3.&nbsp;高级工程师带领团队完成工作，并负责技术攻关.&nbsp;技术分享； '
                    '&nbsp; &nbsp;</p>\n'
                    '<p><br></p>\n'
                    '<p>岗位要求：<br></p>\n'
                    '<p>1.拥有5年以上开发经验，有使用python框架开发Restful&nbsp;API的经验，例如&nbsp;flask/django/tornado；<br>2.有互联网公司后台服务的开发经验，掌握数据库(MySQL).&nbsp;网络编程等方面的工作原理；<br>3.有良好的算法和数据结构基础，及很强的自学能力；<br>4.善于思考，能提出高质量的问题，系统性地分析并从根源上解决问题；<br>5.沟通能力良好，善于团队合作。 '
                    '&nbsp; &nbsp;</p>',
 'art_education': '本科',
 'art_first_type': '开发|测试|运维类',
 'art_jobNature': '全职',
 'art_position': '宝安区',
 'art_salary': '20k-40k',
 'art_second_type': '后端开发',
 'art_third_type': '其他后端开发',
 'art_time': '2019-11-06 11:14:33',
 'art_title': 'Python后台架构师',
 'art_work_year': '5-10年',
 'compangy_full_position': ', -\n'
                           '                    , -\n'
                           '                    ,\n'
                           '                                            - '
                           '宝安区互联网产业基地A区（东北门）5栋108（党群服务中心旁）\n'
                           '                                                            '
                           ',',
 'company_financestage': 'B轮',
 'company_hitags': '',
 'company_label_list': '股票期权,定期体检,下午茶,年度旅游',
 'company_size': '150-500人',
 'company_type': '移动互联网',
 'fingerprint': '1baad2c6f357bb07e49e4d417900cec8',
 'positionId': 4246526}
Traceback (most recent call last):
  File "c:\programdata\anaconda3\envs\spiderpath\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy\lagouzhaopin\lagouzhaopin\pipelines.py", line 70, in process_item
    art.suggest = gen_suggest(LagouType._doc_type.index,((art.art_title,10),(art.art_position,7),
  File "E:\scrapy\lagouzhaopin\lagouzhaopin\pipelines.py", line 32, in gen_suggest
    words = es.indices.analyze(index=index, analyzer='ik_max_word',params={'filter':['lowercase']}, body=text)
  File "c:\programdata\anaconda3\envs\spiderpath\lib\site-packages\elasticsearch\client\utils.py", line 73, in _wrapped
    return func(*args, params=params, **kwargs)
  File "c:\programdata\anaconda3\envs\spiderpath\lib\site-packages\elasticsearch\client\indices.py", line 32, in analyze
    '_analyze'), params=params, body=body)
  File "c:\programdata\anaconda3\envs\spiderpath\lib\site-packages\elasticsearch\transport.py", line 312, in perform_request
    status, headers, data = connection.perform_request(method, url, params, body, ignore=ignore, timeout=timeout)
  File "c:\programdata\anaconda3\envs\spiderpath\lib\site-packages\elasticsearch\connection\http_urllib3.py", line 129, in perform_request
    self._raise_error(response.status, raw_data)
  File "c:\programdata\anaconda3\envs\spiderpath\lib\site-packages\elasticsearch\connection\base.py", line 125, in _raise_error
    raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
elasticsearch.exceptions.NotFoundError: TransportError(404, 'index_not_found_exception', 'no such index')
2019-11-06 13:22:05 [scrapy.core.scraper] ERROR: Error processing {'art_company_id': 130397,
 'art_company_name': '深圳小步网络科技有限公司',
 'art_description': '<p>【岗位职责】</p>\n'
                    '<p>1. 开发与维护业务系统，根据产品需求进行技术迭代</p>\n'
                    '<p>2. 开发与维护基础设施运维平台与内部系统，制定并执行方案</p>\n'
                    '<p>3. 对现有系统进行架构优化，编写高质量代码</p>\n'
                    '<p>&nbsp;</p>\n'
                    '<p>【职位要求】</p>\n'
                    '<p>1. 熟悉基于Python的Web开发，了解Django、Flask等主流框架设计原理</p>\n'
                    '<p>2. 熟悉MySQL/Redis等数据库与事务机制，有较大规模数据集处理经验</p>\n'
                    '<p>3. 有公有云计算平台工作经验，有支付系统设计经验优先</p>\n'
                    '<p>4. 拥有良好的代码习惯，结构清晰命名规范，熟悉pylint和PEP8规范</p>\n'
                    '<p>5. 本科及以上学历，计算机、统计学等相关专业优先，2年工作经验以上。</p>',
 'art_education': '本科',
 'art_first_type': '开发|测试|运维类',
 'art_jobNature': '全职',
 'art_position': '宝安区',
 'art_salary': '20k-40k',
 'art_second_type': '后端开发',
 'art_third_type': '其他后端开发',
 'art_time': '2019-11-06 11:14:33',
 'art_title': 'Python后台架构师',
 'art_work_year': '5-10年',
 'compangy_full_position': ', -\n'
                           '                    , -\n'
                           '                    ,\n'
                           '                                            - '
                           '望京soho\n'
                           '                                                            '
                           ',',
 'company_financestage': 'B轮',
 'company_hitags': '',
 'company_label_list': '股票期权,定期体检,下午茶,年度旅游',
 'company_size': '150-500人',
 'company_type': '移动互联网',
 'fingerprint': '1baad2c6f357bb07e49e4d417900cec8',
 'positionId': 4246526}
Traceback (most recent call last):
  File "c:\programdata\anaconda3\envs\spiderpath\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy\lagouzhaopin\lagouzhaopin\pipelines.py", line 70, in process_item
    art.suggest = gen_suggest(LagouType._doc_type.index,((art.art_title,10),(art.art_position,7),
  File "E:\scrapy\lagouzhaopin\lagouzhaopin\pipelines.py", line 32, in gen_suggest
    words = es.indices.analyze(index=index, analyzer='ik_max_word',params={'filter':['lowercase']}, body=text)
  File "c:\programdata\anaconda3\envs\spiderpath\lib\site-packages\elasticsearch\client\utils.py", line 73, in _wrapped
    return func(*args, params=params, **kwargs)
  File "c:\programdata\anaconda3\envs\spiderpath\lib\site-packages\elasticsearch\client\indices.py", line 32, in analyze
    '_analyze'), params=params, body=body)
  File "c:\programdata\anaconda3\envs\spiderpath\lib\site-packages\elasticsearch\transport.py", line 312, in perform_request
    status, headers, data = connection.perform_request(method, url, params, body, ignore=ignore, timeout=timeout)
  File "c:\programdata\anaconda3\envs\spiderpath\lib\site-packages\elasticsearch\connection\http_urllib3.py", line 129, in perform_request
    self._raise_error(response.status, raw_data)
  File "c:\programdata\anaconda3\envs\spiderpath\lib\site-packages\elasticsearch\connection\base.py", line 125, in _raise_error
    raise HTTP_EXCEPTIONS.get(status_code, TransportError)(status_code, error_message, additional_info)
elasticsearch.exceptions.NotFoundError: TransportError(404, 'index_not_found_exception', 'no such index')
